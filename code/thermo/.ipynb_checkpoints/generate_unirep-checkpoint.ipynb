{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm \n",
    "import glob\n",
    "import re\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import torch\n",
    "from argparse import Namespace\n",
    "from esm.constants import proteinseq_toks\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from esm.modules import TransformerLayer, PositionalEmbedding  # noqa\n",
    "from esm.model import ProteinBertModel\n",
    "import esm\n",
    "import time\n",
    "\n",
    "import tape\n",
    "from tape import ProteinBertModel, TAPETokenizer,UniRepModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdt_motor = pd.read_csv(\"../../data/thermo/pdt_motor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UniRepModel.from_pretrained('babbler-1900')\n",
    "tokenizer = TAPETokenizer(vocab='unirep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSIVVVGANWGDEGKGRIVDYLAGQAGASIRFQGGNNAGHTVVNDLGTFKLHQVPSGVFNPDCLVVLGPGMVISPEKLTVELEEVKASGVTPKLAISDRATLCLPLHALEDTLEEQRLGDGAYGSTRQGIAPAYGDRVMKKAILVGWLKQPDVLVERIQFMLDWKLPQMKAIYPSFEFTQTAQEMADWLLEVSAPWIDAVCNVSMPLKALQAEGKTLLFEAQLGAGRDLIYGEYPWVTSSHVSGAYAGIGGGLPGLRPERVIAVAKAFSSSVGTGTLLTAMENQDEFRKITNEFGATTGRPRDVGYFDAVATKNGVELQAATEVALTKLDCLTGLPDLKICVAYEGAHTENPIWPQTAALKPVYEQMESWSEDITGCRTFEELPKAAQQYVLRIEELLGVPVPMVSVGPGRDEMILR\n"
     ]
    }
   ],
   "source": [
    "seq = pdt_motor[\"seq\"][0]\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = torch.tensor([tokenizer.encode(seq)])\n",
    "output = model(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0].mean(0).cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 2000\n",
    "def generate_embedding_unirep(model,tokenizer,dat,dat_name,out_dir,seq_col):\n",
    "    # initialize network \n",
    "    sequence_embeddings = []\n",
    "    for epoch in range(dat.shape[0]):\n",
    "        seq = dat.iloc[epoch, seq_col]\n",
    "        token_ids = torch.tensor([tokenizer.encode(seq)])\n",
    "        with torch.no_grad():\n",
    "            output = model(token_ids)\n",
    "#         print(output[0][0].device)\n",
    "        sequence_embeddings.append(output[0][0].mean(0).numpy())\n",
    "        if epoch % print_every == 0:\n",
    "            print(f\"At Epoch: %.2f\"% epoch)\n",
    "            print(seq)\n",
    "#             break\n",
    "    sequence_embeddings = np.array(sequence_embeddings)\n",
    "    print(sequence_embeddings.shape)\n",
    "    print(out_dir + '/' + dat_name + \".npy\")\n",
    "    np.save(out_dir + '/' + dat_name + \".npy\", sequence_embeddings)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Epoch: 0.00\n",
      "MSSIVVVGANWGDEGKGRIVDYLAGQAGASIRFQGGNNAGHTVVNDLGTFKLHQVPSGVFNPDCLVVLGPGMVISPEKLTVELEEVKASGVTPKLAISDRATLCLPLHALEDTLEEQRLGDGAYGSTRQGIAPAYGDRVMKKAILVGWLKQPDVLVERIQFMLDWKLPQMKAIYPSFEFTQTAQEMADWLLEVSAPWIDAVCNVSMPLKALQAEGKTLLFEAQLGAGRDLIYGEYPWVTSSHVSGAYAGIGGGLPGLRPERVIAVAKAFSSSVGTGTLLTAMENQDEFRKITNEFGATTGRPRDVGYFDAVATKNGVELQAATEVALTKLDCLTGLPDLKICVAYEGAHTENPIWPQTAALKPVYEQMESWSEDITGCRTFEELPKAAQQYVLRIEELLGVPVPMVSVGPGRDEMILR\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"../../out/201120/\"\n",
    "generate_embedding_unirep(model,tokenizer,pdt_motor,\"pdt_motor_unirep1900\",out_dir,seq_col = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
