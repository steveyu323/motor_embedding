{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cTd-VLr_mbH"
   },
   "source": [
    "# Bidirectional LSTM on Uniref50_01.tsv\n",
    "> The goal of this notebook is to expand the training dataset of LSTM from 8000 protein in a specific pfam to the one-tenth of the UniRef50 dataset. A 64*2 directions LSTM is used to predict the next token. After training is done, we would embed the entire/part of the pfam_motors to see is families are grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3990,
     "status": "ok",
     "timestamp": 1601972751604,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "pydwLMg-hWfd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "# import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# seed = 7\n",
    "# torch.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwj-lD4ik23I"
   },
   "source": [
    "## Get Training Sequence\n",
    "- Compilation of all pfam sequences from the 4 molecular motors-belonging clans\n",
    "- sample 1000 sequences from each of the four clans for learning the hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guaa\n"
     ]
    }
   ],
   "source": [
    "print('guaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 19109,
     "status": "ok",
     "timestamp": 1601972691712,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "WfpPgYKPi1bd",
    "outputId": "a7751fbc-53df-4e0d-84d0-b8980d1f7b10"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "executionInfo": {
     "elapsed": 431,
     "status": "ok",
     "timestamp": 1601972700781,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "MxbZFbSgjW0h",
    "outputId": "5db28d9b-dd5b-40ea-a80a-d77032e8c484"
   },
   "outputs": [],
   "source": [
    "# !ls ./drive/My\\ Drive/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 36107,
     "status": "ok",
     "timestamp": 1601972861387,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "k6I5_kbuivCs"
   },
   "outputs": [],
   "source": [
    "# pfamA_motors = pd.read_csv(\"../data/pfamA_motors.csv\")\n",
    "uniref50_01 = pd.read_csv(\"../data/uniref50_01.tsv\",sep = \"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1601972877222,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "qef-55vNkiaQ",
    "outputId": "9463363a-d360-4119-aead-100938562e8a"
   },
   "outputs": [],
   "source": [
    "uniref50_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1601973281938,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "r---g_9RDEKn",
    "outputId": "d49c1036-2e93-48fb-f47f-c8bd0d73ea5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(846396, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniref50_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1601972894637,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "8neW66hGkmUx",
    "outputId": "4ac455f6-b770-44b6-b390-bd242d76ed34"
   },
   "outputs": [],
   "source": [
    "pfamA_motors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1601972895863,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "WzYlZGZ1lUfm",
    "outputId": "33de7a03-18bf-4784-f271-8bb226e1a86f"
   },
   "outputs": [],
   "source": [
    "pfamA_motors = pfamA_motors.iloc[:,1:]\n",
    "pfamA_motors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1601973034274,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "CTHHv7LvlxRk"
   },
   "outputs": [],
   "source": [
    "clan_train_dat = pfamA_motors.groupby(\"clan\").head(4000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1601973035218,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "1u882Eei4l75",
    "outputId": "63cb6133-9f1a-4f6d-c49f-0f3395e82c42"
   },
   "outputs": [],
   "source": [
    "clan_train_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1601973036081,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "RSzMJtZF4TKu",
    "outputId": "7a146965-b9e9-45df-8f69-4e84916724f8"
   },
   "outputs": [],
   "source": [
    "len(clan_train_dat.loc[:,\"pfamA_acc\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1601973037247,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "3HPQrYp5NKUV",
    "outputId": "14db3226-fae9-4cc4-cd74-f78e5022fc07"
   },
   "outputs": [],
   "source": [
    "clan_train_dat = clan_train_dat.sample(frac=1).reset_index(drop=True)\n",
    "clan_train_dat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1601973038558,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "vXF79cqIgw1O"
   },
   "outputs": [],
   "source": [
    "clan_test_dat = pfamA_motors.loc[~pfamA_motors[\"id\"].isin(clan_train_dat[\"id\"]),:].groupby(\"clan\").head(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1601973039252,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "tDkmtlYHhQrO",
    "outputId": "d0b65bcf-5643-4187-a4b9-2c43dcccc60b"
   },
   "outputs": [],
   "source": [
    "clan_test_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1601973046225,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "lIaph21E4CtO"
   },
   "outputs": [],
   "source": [
    "def df_to_tup(dat):\n",
    "  data = []\n",
    "  for i in range(dat.shape[0]):\n",
    "    row = dat.iloc[i,:]\n",
    "    tup = (row[\"seq\"],row[\"clan\"])\n",
    "    data.append(tup)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3014,
     "status": "ok",
     "timestamp": 1601973069342,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "dU91oG1Nfr1b"
   },
   "outputs": [],
   "source": [
    "clan_training_data = df_to_tup(clan_train_dat)\n",
    "clan_test_data = df_to_tup(clan_test_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1601973076748,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "x5Y2IvAM5dPa",
    "outputId": "626c6fcb-e93e-48c6-b30b-4b5da1bc52dc"
   },
   "outputs": [],
   "source": [
    "for seq,clan in clan_training_data:\n",
    "  print(seq)\n",
    "  print(clan)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1601973080732,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "rjhd2h6EhfQx",
    "outputId": "8c25604e-2038-4c2d-b6c8-4e92280c1611"
   },
   "outputs": [],
   "source": [
    "for seq,clan in clan_test_data:\n",
    "  print(seq)\n",
    "  print(clan)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1601973131437,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "hV8NGyYUvE_R"
   },
   "outputs": [],
   "source": [
    "aminoacid_list = [\n",
    "    'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "    'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'\n",
    "]\n",
    "clan_list = [\"actin_like\",\"tubulin_c\",\"tubulin_binding\",\"p_loop_gtpase\"]\n",
    "        \n",
    "aa_to_ix = dict(zip(aminoacid_list, np.arange(1, 21)))\n",
    "clan_to_ix = dict(zip(clan_list, np.arange(0, 4)))\n",
    "\n",
    "def word_to_index(seq,to_ix):\n",
    "    \"Returns a list of indices (integers) from a list of words.\"\n",
    "    return [to_ix.get(word, 0) for word in seq]\n",
    "\n",
    "ix_to_aa = dict(zip(np.arange(1, 21), aminoacid_list))\n",
    "ix_to_clan = dict(zip(np.arange(0, 4), clan_list))\n",
    "\n",
    "def index_to_word(ixs,ix_to): \n",
    "    \"Returns a list of words, given a list of their corresponding indices.\"\n",
    "    return [ix_to.get(ix, 'X') for ix in ixs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1601973133424,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "UXcX4myBPWkW",
    "outputId": "95d3b581-df70-41af-9ebe-5b78c810ba1d"
   },
   "outputs": [],
   "source": [
    "clan_to_ix.get(\"actin_like\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1601973136954,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "8ZNd98aO3GxB"
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq):\n",
    "    idxs = word_to_index(seq[0:-1],aa_to_ix)\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_labels(seq):\n",
    "    idxs = word_to_index(seq[1:],aa_to_ix)\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1601973143123,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "o8FpiTrchWfi"
   },
   "outputs": [],
   "source": [
    "# set device\n",
    "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1601973143305,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "lpsVAip-h45-",
    "outputId": "331995f1-8573-4780-8c17-3b48a2d4441f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1601973243782,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "WiTiuLuihWfm"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = len(aminoacid_list) + 1\n",
    "num_layers = 1\n",
    "hidden_size = 64\n",
    "output_size = len(aminoacid_list) + 1\n",
    "embedding_size= 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1601973245236,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "zoamaFX42bqU",
    "outputId": "a73b7621-7a44-4299-8816-ebecfc983600"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1601973245706,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "Demgi-XuhWfv"
   },
   "outputs": [],
   "source": [
    "# Create Bidirectional LSTM\n",
    "class BRNN(nn.Module):\n",
    "    def __init__(self,input_size, embedding_size, hidden_size, num_layers, output_size):\n",
    "        super(BRNN,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.log_softmax = nn.LogSoftmax(dim= 1)\n",
    "        self.aa_embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_size, \n",
    "                            hidden_size = hidden_size,\n",
    "                            num_layers = num_layers, \n",
    "                            bidirectional = True)\n",
    "        #hidden_state: a forward and a backward state for each layer of LSTM\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "    \n",
    "    def aa_encoder(self, input): \n",
    "        \"Helper function to map single aminoacids to the embedding space.\"\n",
    "        projected = self.embedding(input)\n",
    "        return projected \n",
    "    \n",
    "\n",
    "    def forward(self,seq):\n",
    "        # embed each aa to the embedded space\n",
    "        embedding_tensor = self.aa_embedding(seq)\n",
    "\n",
    "        # initialization could be neglected as the default is 0 for h0 and c0\n",
    "        # initialize hidden state\n",
    "        # h0 = torch.zeros(self.num_layers*2,x.size(0),self.hidden_size).to(device)\n",
    "        # initialize cell_state\n",
    "        # c0 = torch.zeros(self.num_layers*2,x.size(0),self.hidden_size).to(device)\n",
    "\n",
    "        # shape(seq_len = len(sequence), batch_size = 1, input_size = -1)\n",
    "        # (5aa,1 sequence per batch, 10-dimension embedded vector)\n",
    "\n",
    "        #output of shape (seq_len, batch, num_directions * hidden_size):\n",
    "        out, (hn, cn) = self.lstm(embedding_tensor.view(len(seq), 1, -1))\n",
    "        # decoded_space = self.fc(out.view(len(seq), -1))\n",
    "        decoded_space = self.fc(out.view(len(seq), -1))\n",
    "        decoded_scores = F.log_softmax(decoded_space, dim=1)\n",
    "        return decoded_scores, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1601973246971,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "jBffwjrchWfy"
   },
   "outputs": [],
   "source": [
    "# initialize network\n",
    "model = BRNN(input_size, embedding_size, hidden_size, num_layers, output_size).to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1601973249755,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "sH6BdzpNhWf1",
    "outputId": "b2e66373-ede5-486a-e79b-ed41ade83b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0509, -3.1128, -3.1330,  ..., -2.9522, -3.1162, -3.0967],\n",
      "        [-3.0757, -3.1047, -3.1458,  ..., -2.9539, -3.1117, -3.0991],\n",
      "        [-3.0765, -3.1058, -3.1476,  ..., -2.9678, -3.1096, -3.1037],\n",
      "        ...,\n",
      "        [-3.0390, -3.0004, -3.0610,  ..., -2.9404, -3.1320, -3.1425],\n",
      "        [-3.0409, -3.0239, -3.0719,  ..., -2.9277, -3.1244, -3.0955],\n",
      "        [-3.0469, -3.0448, -3.1066,  ..., -2.9487, -3.1077, -3.0804]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = Variable(prepare_sequence(uniref50_01.iloc[0,1]))\n",
    "    inputs = inputs.to(device = device)\n",
    "    aa_scores, _ = model(inputs)\n",
    "    print( aa_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1601973251565,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "wvi-wR5FNhlx",
    "outputId": "a4700213-4319-4b60-e9c4-5f225b8e6cb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45353, 21])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 210065,
     "status": "error",
     "timestamp": 1601973595742,
     "user": {
      "displayName": "Changhua Yu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-90F37RT3kEYUkfMbPCPW4fpyitBWQwIqJAXE=s64",
      "userId": "11998671452641273992"
     },
     "user_tz": 420
    },
    "id": "77fyNs4lhWf4",
    "outputId": "b1c37a9e-490c-4a98-bc77-c958d1a4a8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Epoch: 9000.00\n",
      "Loss 1.51\n",
      "At Epoch: 29000.00\n",
      "Loss 0.00\n",
      "At Epoch: 30000.00\n",
      "Loss 0.00\n",
      "At Epoch: 31000.00\n",
      "Loss 0.00\n",
      "At Epoch: 32000.00\n",
      "Loss 0.00\n",
      "At Epoch: 33000.00\n",
      "Loss 0.00\n",
      "At Epoch: 34000.00\n",
      "Loss 0.00\n",
      "At Epoch: 35000.00\n",
      "Loss 0.00\n",
      "At Epoch: 36000.00\n",
      "Loss 0.00\n",
      "At Epoch: 37000.00\n",
      "Loss 0.00\n",
      "At Epoch: 38000.00\n",
      "Loss 0.00\n",
      "At Epoch: 39000.00\n",
      "Loss 0.00\n",
      "At Epoch: 40000.00\n",
      "Loss 0.00\n",
      "At Epoch: 41000.00\n",
      "Loss 0.00\n",
      "At Epoch: 42000.00\n",
      "Loss 0.00\n",
      "At Epoch: 43000.00\n",
      "Loss 0.00\n",
      "At Epoch: 44000.00\n",
      "Loss 0.00\n",
      "At Epoch: 45000.00\n",
      "Loss 0.00\n",
      "At Epoch: 46000.00\n",
      "Loss 0.00\n",
      "At Epoch: 47000.00\n",
      "Loss 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-61a0268bd932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/central/software/python/3.7.0/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/central/software/python/3.7.0/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train Network\n",
    "\n",
    "print_every = 1000\n",
    "\n",
    "for epoch in np.arange(0, uniref50_01.shape[0]): \n",
    "    seq = uniref50_01.iloc[epoch, 1]\n",
    "    if(len(seq)>4000):\n",
    "        continue\n",
    "    # Step 1. Remember that Pytorch accumulates gradients.\n",
    "    # We need to clear them out before each instance\n",
    "    \n",
    "    # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "    # Tensors of word indices.\n",
    "    sentence_in = prepare_sequence(seq)\n",
    "    targets = prepare_labels(seq)\n",
    "    \n",
    "    sentence_in = sentence_in.to(device = device)\n",
    "    targets = targets.to(device = device)\n",
    "    \n",
    "    # Step 3. Run our forward pass.\n",
    "    model.zero_grad()\n",
    "    aa_scores, hn = model(sentence_in)\n",
    "\n",
    "    # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "    #  calling optimizer.step()\n",
    "    \n",
    "    loss = loss_function(aa_scores, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print(f\"At Epoch: %.2f\"% epoch)\n",
    "        print(f\"Loss %.6f\"% loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../data/bidirectional_lstm_uniref_201009.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM+MIpkTuKXuQKI73EUJ9u7",
   "collapsed_sections": [],
   "name": "bidirectional_lstm_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
