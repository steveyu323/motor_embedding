{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "> 201025: This notebook generate embedding vectors for pfam_motors, df_dev, and motor_toolkit from the models that currently finished training:\n",
    "    - lstm5\n",
    "        - evotune_lstm_5_balanced.pt\n",
    "        - evotune_lstm_5_balanced_target.pt\n",
    "        - mini_lstm_5_balanced.pt\n",
    "        - mini_lstm_5_balanced_target.pt\n",
    "    - transformer_encoder\n",
    "        - evotune_seq2seq_encoder_balanced.pt\n",
    "        - evotune_seq2seq_encoder_balanced_target.pt\n",
    "        - mini_seq2seq_encoder_balanced.pt\n",
    "        - mini_seq2seq_encoder_balanced_target.pt\n",
    "    - seq2seq_attention_mini\n",
    "        - transformer_encoder_201025.pt\n",
    "        - evotune_transformerencoder_balanced.pt\n",
    "        - evotune_transformerencoder_balanced_target.pt\n",
    "        - mini_evotune_transformerencoder_balanced.pt\n",
    "        - mini_evotune_transformerencoder_balanced_target.pt\n",
    "        \n",
    "\n",
    "- output for motor_toolkit,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "# import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfamA_motors = pd.read_csv(\"../../data/pfamA_motors.csv\")\n",
    "df_dev = pd.read_csv(\"../../data/df_dev.csv\")\n",
    "motor_toolkit = pd.read_csv(\"../../data/motor_tookits.csv\")\n",
    "\n",
    "aminoacid_list = [\n",
    "    'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "    'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y'\n",
    "]\n",
    "clan_list = [\"actin_like\",\"tubulin_c\",\"tubulin_binding\",\"p_loop_gtpase\"]\n",
    "        \n",
    "aa_to_ix = dict(zip(aminoacid_list, np.arange(1, 21)))\n",
    "clan_to_ix = dict(zip(clan_list, np.arange(0, 4)))\n",
    "\n",
    "def word_to_index(seq,to_ix):\n",
    "    \"Returns a list of indices (integers) from a list of words.\"\n",
    "    return [to_ix.get(word, 0) for word in seq]\n",
    "\n",
    "ix_to_aa = dict(zip(np.arange(1, 21), aminoacid_list))\n",
    "ix_to_clan = dict(zip(np.arange(0, 4), clan_list))\n",
    "\n",
    "def index_to_word(ixs,ix_to): \n",
    "    \"Returns a list of words, given a list of their corresponding indices.\"\n",
    "    return [ix_to.get(ix, 'X') for ix in ixs]\n",
    "\n",
    "def prepare_sequence(seq):\n",
    "    idxs = word_to_index(seq[0:-1],aa_to_ix)\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_labels(seq):\n",
    "    idxs = word_to_index(seq[1:],aa_to_ix)\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def prepare_eval(seq):\n",
    "    idxs = word_to_index(seq[:],aa_to_ix)\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "prepare_labels('YCHXXXXX')\n",
    "\n",
    "# set device\n",
    "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = len(aminoacid_list) + 1\n",
    "num_layers = 1\n",
    "hidden_size = 128\n",
    "output_size = len(aminoacid_list) + 1\n",
    "embedding_size= 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create Bidirectional LSTM\n",
    "class BRNN(nn.Module):\n",
    "    def __init__(self,input_size, embedding_size, hidden_size, num_layers, output_size):\n",
    "        super(BRNN,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.log_softmax = nn.LogSoftmax(dim= 1)\n",
    "        self.aa_embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size = embedding_size, \n",
    "                            hidden_size = hidden_size,\n",
    "                            num_layers = num_layers, \n",
    "                            bidirectional = True)\n",
    "        #hidden_state: a forward and a backward state for each layer of LSTM\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "    \n",
    "    def aa_encoder(self, input): \n",
    "        \"Helper function to map single aminoacids to the embedding space.\"\n",
    "        projected = self.embedding(input)\n",
    "        return projected \n",
    "    \n",
    "\n",
    "    def forward(self,seq):\n",
    "        # embed each aa to the embedded space\n",
    "        embedding_tensor = self.aa_embedding(seq)\n",
    "\n",
    "        # initialization could be neglected as the default is 0 for h0 and c0\n",
    "        # initialize hidden state\n",
    "        # h0 = torch.zeros(self.num_layers*2,x.size(0),self.hidden_size).to(device)\n",
    "        # initialize cell_state\n",
    "        # c0 = torch.zeros(self.num_layers*2,x.size(0),self.hidden_size).to(device)\n",
    "\n",
    "        # shape(seq_len = len(sequence), batch_size = 1, input_size = -1)\n",
    "        # (5aa,1 sequence per batch, 10-dimension embedded vector)\n",
    "\n",
    "        #output of shape (seq_len, batch, num_directions * hidden_size):\n",
    "        out, (hn, cn) = self.lstm(embedding_tensor.view(len(seq), 1, -1))\n",
    "        # decoded_space = self.fc(out.view(len(seq), -1))\n",
    "        decoded_space = self.fc(out.view(len(seq), -1))\n",
    "        decoded_scores = F.log_softmax(decoded_space, dim=1)\n",
    "        return decoded_scores, hn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "model = BRNN(input_size, embedding_size, hidden_size, num_layers, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"../data/bidirectional_lstm_5_201008.pt\"))\n",
    "model.eval()\n",
    "hn_vector = []\n",
    "print_every = 100\n",
    "for epoch in np.arange(0, motor_toolkit.shape[0]):   \n",
    "    with torch.no_grad():\n",
    "        seq = motor_toolkit.iloc[epoch, 7]\n",
    "        sentence_in = prepare_eval(seq)\n",
    "        sentence_in = sentence_in.to(device = device)\n",
    "        decoded_scores, hn = model(sentence_in)\n",
    "        hn_vector.append(hn.cpu().detach().numpy().reshape(1,-1))\n",
    "    if epoch % print_every == 0:\n",
    "      print(f\"At Epoch: %.2f\"% epoch)\n",
    "hn_vector = np.array(hn_vector)\n",
    "hn_vector = np.squeeze(hn_vector, axis=1)\n",
    "print(hn_vector.shape)\n",
    "np.save(\"../data/hn_lstm5_motortoolkit.npy\", hn_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
